{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the pre-trained Haar Cascade for face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Initialize video capture (0 is the default camera)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Variable to store the number of faces detected\n",
    "face_count = 0\n",
    "\n",
    "# Function to detect faces and update the face count\n",
    "def detect_faces(frame):\n",
    "    global face_count\n",
    "    # Convert frame to grayscale for better detection\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect faces in the frame\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    \n",
    "    # Update the face count with the number of faces detected\n",
    "    face_count = len(faces)\n",
    "    \n",
    "    # Draw rectangles around the faces detected\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "    # Return the modified frame\n",
    "    return frame\n",
    "\n",
    "# Main loop for processing the video stream\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Detect faces and update the frame\n",
    "    frame = detect_faces(frame)\n",
    "    \n",
    "    # Display the current face count on the frame\n",
    "    cv2.putText(frame, f'Face Count: {face_count}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    \n",
    "    # Show the frame with the face count\n",
    "    cv2.imshow('Face Counter', frame)\n",
    "    \n",
    "    # Break the loop if the user presses 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Lock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the pre-trained Haar Cascade for face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Initialize video capture (0 is the default camera)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Parameters\n",
    "line_position = 250  # Y-coordinate of the counting line\n",
    "offset = 30  # Offset to create tolerance for crossing detection\n",
    "people_count = 0  # To store the count of people entering\n",
    "\n",
    "# Store the previous Y-coordinate of faces to track direction\n",
    "previous_faces = []\n",
    "\n",
    "# Function to detect faces and count people entering\n",
    "def detect_and_count_faces(frame):\n",
    "    global people_count, previous_faces\n",
    "    \n",
    "    # Convert frame to grayscale for better face detection\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect faces in the frame\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    \n",
    "    current_faces = []\n",
    "    \n",
    "    # Draw the counting line\n",
    "    cv2.line(frame, (0, line_position), (frame.shape[1], line_position), (0, 255, 0), 2)\n",
    "    \n",
    "    # Process each face detected\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Draw rectangle around each face\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "        \n",
    "        # Calculate the center of the face\n",
    "        cx = int(x + w / 2)\n",
    "        cy = int(y + h / 2)\n",
    "        \n",
    "        # Draw the center point\n",
    "        cv2.circle(frame, (cx, cy), 5, (0, 0, 255), -1)\n",
    "        \n",
    "        # Store the Y-coordinate of the center of the face for current frame\n",
    "        current_faces.append(cy)\n",
    "        \n",
    "        # Check if face crosses the line from below to above (entering)\n",
    "        for prev_y in previous_faces:\n",
    "            if prev_y < line_position and cy >= line_position - offset:\n",
    "                people_count += 1\n",
    "                break\n",
    "    \n",
    "    # Update the list of previous face Y-coordinates for the next frame\n",
    "    previous_faces = current_faces\n",
    "    \n",
    "    return frame\n",
    "\n",
    "# Main loop to process video\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Resize frame to make it easier to process\n",
    "    frame = cv2.resize(frame, (640, 480))\n",
    "    \n",
    "    # Detect faces and count people\n",
    "    frame = detect_and_count_faces(frame)\n",
    "    \n",
    "    # Display the count of people on the frame\n",
    "    cv2.putText(frame, f'Face Detected Locked', (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "    \n",
    "    # Show the video frame with detection\n",
    "    cv2.imshow('Face Detection', frame)\n",
    "    \n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Choose an option:\n",
      "1: Register a new face\n",
      "2: Start video feed and recognize faces\n",
      "q: Quit\n",
      "No faces registered yet. Please register a face first.\n",
      "\n",
      "Choose an option:\n",
      "1: Register a new face\n",
      "2: Start video feed and recognize faces\n",
      "q: Quit\n",
      "No faces registered yet. Please register a face first.\n",
      "\n",
      "Choose an option:\n",
      "1: Register a new face\n",
      "2: Start video feed and recognize faces\n",
      "q: Quit\n",
      "Press 'q' to capture your face for registration.\n",
      "\n",
      "Choose an option:\n",
      "1: Register a new face\n",
      "2: Start video feed and recognize faces\n",
      "q: Quit\n",
      "\n",
      "Choose an option:\n",
      "1: Register a new face\n",
      "2: Start video feed and recognize faces\n",
      "q: Quit\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize variables to store registered face encodings and their names\n",
    "known_face_encodings = []\n",
    "known_face_names = []\n",
    "\n",
    "# Directory to store registered face images\n",
    "REGISTRATION_DIR = 'registered_faces'\n",
    "if not os.path.exists(REGISTRATION_DIR):\n",
    "    os.makedirs(REGISTRATION_DIR)\n",
    "\n",
    "# Function to register a face with a name\n",
    "def register_face(name):\n",
    "    # Start the webcam\n",
    "    video_capture = cv2.VideoCapture(0)\n",
    "    print(\"Press 'q' to capture your face for registration.\")\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = video_capture.read()\n",
    "        cv2.imshow('Video - Register Face', frame)\n",
    "        \n",
    "        # Wait for the user to press 'q' to capture\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            # Save the captured image\n",
    "            image_path = os.path.join(REGISTRATION_DIR, f\"{name}.jpg\")\n",
    "            cv2.imwrite(image_path, frame)\n",
    "            break\n",
    "    \n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    # Load the captured image and encode the face\n",
    "    image = face_recognition.load_image_file(image_path)\n",
    "    face_encoding = face_recognition.face_encodings(image)[0]\n",
    "    \n",
    "    # Store the face encoding and name\n",
    "    known_face_encodings.append(face_encoding)\n",
    "    known_face_names.append(name)\n",
    "\n",
    "# Function to recognize faces in a live video feed\n",
    "def recognize_faces():\n",
    "    video_capture = cv2.VideoCapture(0)\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = video_capture.read()\n",
    "        rgb_frame = frame[:, :, ::-1]  # Convert BGR to RGB for face_recognition\n",
    "        \n",
    "        # Find all faces and their encodings in the current frame\n",
    "        face_locations = face_recognition.face_locations(rgb_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "        \n",
    "        # Loop over each face found in the frame to check if it matches a known face\n",
    "        for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "            # Compare face encoding to known faces\n",
    "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "            name = \"Unknown\"\n",
    "            \n",
    "            face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "            best_match_index = np.argmin(face_distances)\n",
    "            if matches[best_match_index]:\n",
    "                name = known_face_names[best_match_index]\n",
    "            \n",
    "            # Draw a box around the face and label with name\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "            cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 255, 0), cv2.FILLED)\n",
    "            cv2.putText(frame, name, (left + 6, bottom - 6), cv2.FONT_HERSHEY_DUPLEX, 1.0, (255, 255, 255), 1)\n",
    "        \n",
    "        # Display the video feed\n",
    "        cv2.imshow('Video - Face Recognition', frame)\n",
    "        \n",
    "        # Exit the feed when 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Main function to interact with the user\n",
    "def main():\n",
    "    while True:\n",
    "        print(\"\\nChoose an option:\")\n",
    "        print(\"1: Register a new face\")\n",
    "        print(\"2: Start video feed and recognize faces\")\n",
    "        print(\"q: Quit\")\n",
    "        \n",
    "        choice = input(\"Enter your choice: \")\n",
    "        \n",
    "        if choice == '1':\n",
    "            name = input(\"Enter the name of the person to register: \")\n",
    "            register_face(name)\n",
    "        elif choice == '2':\n",
    "            if len(known_face_encodings) == 0:\n",
    "                print(\"No faces registered yet. Please register a face first.\")\n",
    "            else:\n",
    "                recognize_faces()\n",
    "        elif choice == 'q':\n",
    "            break\n",
    "        else:\n",
    "            print(\"Invalid choice. Please try again.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thea",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
